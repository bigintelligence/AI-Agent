{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mE_0i3z_L7cK"
   },
   "source": [
    "# Components in LlamaIndex\n",
    "\n",
    "This notebook is part of the [Hugging Face Agents Course](https://www.hf.co/learn/agents-course), a free Course from beginner to expert, where you learn to build Agents.\n",
    "\n",
    "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)\n",
    "\n",
    "Alfred is hosting a party and needs to be able to find relevant information on personas that will be attending the party. Therefore, we will use a `QueryEngine` to index and search through a database of personas.\n",
    "\n",
    "## Let's install the dependencies\n",
    "\n",
    "We will install the dependencies for this unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vmDDhVgNL7cP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index datasets llama-index-callbacks-arize-phoenix llama-index-vector-stores-chroma llama-index-llms-huggingface-api -U -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2yTrXMrL7cS"
   },
   "source": [
    "And, let's log in to Hugging Face to use serverless Inference APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hOMOWeMfL7cU"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b2d0af84bd4a908385750e3f358d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWIDDEe_L7cX"
   },
   "source": [
    "## Create a `QueryEngine` for retrieval augmented generation\n",
    "\n",
    "### Setting up the persona database\n",
    "\n",
    "We will be using personas from the [dvilasuero/finepersonas-v0.1-tiny dataset](https://huggingface.co/datasets/dvilasuero/finepersonas-v0.1-tiny). This dataset contains 5K personas that will be attending the party!\n",
    "\n",
    "Let's load the dataset and store it as files in the `data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j2Mqoy-lL7cY"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f27305b3d34ae88b04dd5e8b03ed64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/618 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dante\\.cache\\huggingface\\hub\\datasets--dvilasuero--finepersonas-v0.1-tiny. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef61a7e87b9e48378bc6db72c46313d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/35.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a1c33a33e64945884346aaa052f351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "dataset = load_dataset(path=\"dvilasuero/finepersonas-v0.1-tiny\", split=\"train\")\n",
    "\n",
    "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "for i, persona in enumerate(dataset):\n",
    "    with open(Path(\"data\") / f\"persona_{i}.txt\", \"w\") as f:\n",
    "        f.write(persona[\"persona\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tTwuLD5L7cZ"
   },
   "source": [
    "Awesome, now we have a local directory with all the personas that will be attending the party, we can load and index!\n",
    "\n",
    "### Loading and embedding persona documents\n",
    "\n",
    "We will use the `SimpleDirectoryReader` to load the persona descriptions from the `data` directory. This will return a list of `Document` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "R4B9F4LjL7ca",
    "outputId": "06676004-9e18-42b4-f8f9-b8a5d1b09d41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\"data\")\n",
    "documents = reader.load_data()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSnA9hzHL7cb"
   },
   "source": [
    "Now we have a list of `Document` objects, we can use the `IngestionPipeline` to create nodes from the documents and prepare them for the `QueryEngine`. We will use the `SentenceSplitter` to split the documents into smaller chunks and the `HuggingFaceInferenceAPIEmbedding` to embed the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_index_embeddings_huggingface_api"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Obtaining dependency information for llama_index_embeddings_huggingface_api from https://files.pythonhosted.org/packages/43/45/0d95c55b101643c5eaf2d51040a75f4d6616403a561e7e44f3e0c37c66b6/llama_index_embeddings_huggingface_api-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_embeddings_huggingface_api-0.3.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: huggingface-hub[inference]>=0.19.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama_index_embeddings_huggingface_api) (0.29.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama_index_embeddings_huggingface_api) (0.12.25)\n",
      "Collecting llama-index-utils-huggingface<0.4.0,>=0.3.0 (from llama_index_embeddings_huggingface_api)\n",
      "  Obtaining dependency information for llama-index-utils-huggingface<0.4.0,>=0.3.0 from https://files.pythonhosted.org/packages/8f/7e/6935fdf9c520f4f8ba9256d5698d8bbbebd1e62a64e3387885e5318542e6/llama_index_utils_huggingface-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_utils_huggingface-0.3.0-py3-none-any.whl.metadata (697 bytes)\n",
      "Requirement already satisfied: filelock in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (3.11.13)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (2.0.38)\n",
      "Requirement already satisfied: dataclasses-json in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (1.2.0)\n",
      "Requirement already satisfied: httpx in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (1.18.3)\n",
      "Requirement already satisfied: click in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub[inference]>=0.19.0->llama_index_embeddings_huggingface_api) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (3.26.1)\n",
      "Requirement already satisfied: anyio in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama_index_embeddings_huggingface_api) (1.3.1)\n",
      "Downloading llama_index_embeddings_huggingface_api-0.3.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading llama_index_utils_huggingface-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Installing collected packages: llama-index-utils-huggingface, llama_index_embeddings_huggingface_api\n",
      "Successfully installed llama-index-utils-huggingface-0.3.0 llama_index_embeddings_huggingface_api-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_index_embeddings_huggingface_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_j3_J0IVL7ce",
    "outputId": "3eb80625-34f3-4673-add6-62a04422b94b"
   },
   "outputs": [
    {
     "ename": "ClientResponseError",
     "evalue": "402, message='Payment Required', url='https://router.huggingface.co/hf-inference/pipeline/feature-extraction/Qwen/Qwen2.5-Coder-32B-Instruct'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientResponseError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m      9\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m IngestionPipeline(\n\u001b[0;32m     10\u001b[0m     transformations\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     11\u001b[0m         SentenceSplitter(),\n\u001b[0;32m     12\u001b[0m         HuggingFaceInferenceAPIEmbedding(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen/Qwen2.5-Coder-32B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     13\u001b[0m     ]\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# run the pipeline sync or async\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m pipeline\u001b[38;5;241m.\u001b[39marun(documents\u001b[38;5;241m=\u001b[39mdocuments[:\u001b[38;5;241m10\u001b[39m])\n\u001b[0;32m     18\u001b[0m nodes\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:368\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    361\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    362\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    366\u001b[0m )\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\llama_index\\core\\ingestion\\pipeline.py:731\u001b[0m, in \u001b[0;36mIngestionPipeline.arun\u001b[1;34m(self, show_progress, documents, nodes, cache_collection, in_place, store_doc_text, num_workers, **kwargs)\u001b[0m\n\u001b[0;32m    729\u001b[0m         nodes: Sequence[BaseNode] \u001b[38;5;241m=\u001b[39m reduce(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: x \u001b[38;5;241m+\u001b[39m y, result, [])  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 731\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m arun_transformations(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    732\u001b[0m         nodes_to_run,\n\u001b[0;32m    733\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformations,\n\u001b[0;32m    734\u001b[0m         show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[0;32m    735\u001b[0m         cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    736\u001b[0m         cache_collection\u001b[38;5;241m=\u001b[39mcache_collection,\n\u001b[0;32m    737\u001b[0m         in_place\u001b[38;5;241m=\u001b[39min_place,\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    739\u001b[0m     )\n\u001b[0;32m    740\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[0;32m    742\u001b[0m nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\llama_index\\core\\ingestion\\pipeline.py:134\u001b[0m, in \u001b[0;36marun_transformations\u001b[1;34m(nodes, transformations, in_place, cache, cache_collection, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m cached_nodes\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 134\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transform\u001b[38;5;241m.\u001b[39macall(nodes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    135\u001b[0m         cache\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;28mhash\u001b[39m, nodes, collection\u001b[38;5;241m=\u001b[39mcache_collection)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py:456\u001b[0m, in \u001b[0;36mBaseEmbedding.acall\u001b[1;34m(self, nodes, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21macall\u001b[39m(\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m, nodes: Sequence[BaseNode], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    455\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence[BaseNode]:\n\u001b[1;32m--> 456\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maget_text_embedding_batch(\n\u001b[0;32m    457\u001b[0m         [node\u001b[38;5;241m.\u001b[39mget_content(metadata_mode\u001b[38;5;241m=\u001b[39mMetadataMode\u001b[38;5;241m.\u001b[39mEMBED) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes],\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    459\u001b[0m     )\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(nodes, embeddings):\n\u001b[0;32m    462\u001b[0m         node\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:368\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    361\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[0;32m    362\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m    366\u001b[0m )\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\llama_index\\core\\base\\embeddings\\base.py:407\u001b[0m, in \u001b[0;36mBaseEmbedding.aget_text_embedding_batch\u001b[1;34m(self, texts, show_progress)\u001b[0m\n\u001b[0;32m    405\u001b[0m             nested_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39membeddings_coroutines)\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 407\u001b[0m         nested_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39membeddings_coroutines)\n\u001b[0;32m    409\u001b[0m result_embeddings \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    410\u001b[0m     embedding \u001b[38;5;28;01mfor\u001b[39;00m embeddings \u001b[38;5;129;01min\u001b[39;00m nested_embeddings \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m embeddings\n\u001b[0;32m    411\u001b[0m ]\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (event_id, text_batch), embeddings \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    414\u001b[0m     callback_payloads, nested_embeddings\n\u001b[0;32m    415\u001b[0m ):\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\llama_index\\embeddings\\huggingface_api\\base.py:212\u001b[0m, in \u001b[0;36mHuggingFaceInferenceAPIEmbedding._aget_text_embeddings\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_aget_text_embeddings\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Embedding]:\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_embed_bulk(\n\u001b[0;32m    213\u001b[0m         texts\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    214\u001b[0m             format_text(text, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_instruction)\n\u001b[0;32m    215\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts\n\u001b[0;32m    216\u001b[0m         ]\n\u001b[0;32m    217\u001b[0m     )\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\llama_index\\embeddings\\huggingface_api\\base.py:167\u001b[0m, in \u001b[0;36mHuggingFaceInferenceAPIEmbedding._async_embed_bulk\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03mEmbed a sequence of text, in parallel and asynchronously.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03mNOTE: this uses an externally created asyncio event loop.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    166\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_embed_single(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\llama_index\\embeddings\\huggingface_api\\base.py:146\u001b[0m, in \u001b[0;36mHuggingFaceInferenceAPIEmbedding._async_embed_single\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_async_embed_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Embedding:\n\u001b[1;32m--> 146\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_client\u001b[38;5;241m.\u001b[39mfeature_extraction(text)\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(embedding\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m embedding\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\huggingface_hub\\inference\\_generated\\_async_client.py:1159\u001b[0m, in \u001b[0;36mAsyncInferenceClient.feature_extraction\u001b[1;34m(self, text, normalize, prompt_name, truncate, truncation_direction, model)\u001b[0m\n\u001b[0;32m   1146\u001b[0m provider_helper \u001b[38;5;241m=\u001b[39m get_provider_helper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprovider, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature-extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1147\u001b[0m request_parameters \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39mprepare_request(\n\u001b[0;32m   1148\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   1149\u001b[0m     parameters\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[0;32m   1158\u001b[0m )\n\u001b[1;32m-> 1159\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_post(request_parameters)\n\u001b[0;32m   1160\u001b[0m np \u001b[38;5;241m=\u001b[39m _import_numpy()\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(_bytes_to_dict(response), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\huggingface_hub\\inference\\_generated\\_async_client.py:331\u001b[0m, in \u001b[0;36mAsyncInferenceClient._inner_post\u001b[1;34m(self, request_parameters, stream)\u001b[0m\n\u001b[0;32m    329\u001b[0m     error\u001b[38;5;241m.\u001b[39mresponse_error_payload \u001b[38;5;241m=\u001b[39m response_error_payload\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m session\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m session\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\huggingface_hub\\inference\\_generated\\_async_client.py:317\u001b[0m, in \u001b[0;36mAsyncInferenceClient._inner_post\u001b[1;34m(self, request_parameters, stream)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _async_yield_from(session, response)\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\aiohttp\\client_reqrep.py:1161\u001b[0m, in \u001b[0;36mClientResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_context:\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m-> 1161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ClientResponseError(\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_info,\n\u001b[0;32m   1163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory,\n\u001b[0;32m   1164\u001b[0m     status\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m   1165\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreason,\n\u001b[0;32m   1166\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1167\u001b[0m )\n",
      "\u001b[1;31mClientResponseError\u001b[0m: 402, message='Payment Required', url='https://router.huggingface.co/hf-inference/pipeline/feature-extraction/Qwen/Qwen2.5-Coder-32B-Instruct'"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface_api import HuggingFaceInferenceAPIEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "import os\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=\"xxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "# create the pipeline with transformations\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(),\n",
    "        HuggingFaceInferenceAPIEmbedding(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# run the pipeline sync or async\n",
    "nodes = await pipeline.arun(documents=documents[:10])\n",
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_ANdNyIL7cf"
   },
   "source": [
    "As, you can see, we have created a list of `Node` objects, which are just chunks of text from the original documents. Let's explore how we can add these nodes to a vector store.\n",
    "\n",
    "### Storing and indexing documents\n",
    "\n",
    "Since we are using an ingestion pipeline, we can directly attach a vector store to the pipeline to populate it.\n",
    "In this case, we will use `Chroma` to store our documents.\n",
    "Let's run the pipeline again with the vector store attached.\n",
    "The `IngestionPipeline` caches the operations so this should be fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxruntime in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (1.21.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from onnxruntime) (2.2.3)\n",
      "Requirement already satisfied: packaging in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from onnxruntime) (24.2)\n",
      "Requirement already satisfied: protobuf in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from onnxruntime) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from onnxruntime) (1.13.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\dev\\ai-agent\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.5.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NZSj-3kaL7cg",
    "outputId": "564abaf3-761f-4936-ffc3-c7dda015a0ce"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The onnxruntime python package is not installed. Please install it with `pip install onnxruntime`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\chromadb\\utils\\embedding_functions\\onnx_mini_lm_l6_v2.py:63\u001b[0m, in \u001b[0;36mONNXMiniLM_L6_V2.__init__\u001b[1;34m(self, preferred_providers)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# Equivalent to import onnxruntime\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mort \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43monnxruntime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\onnxruntime\\__init__.py:61\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m import_capi_exception:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m import_capi_exception\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01monnxruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnxruntime_inference_collection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     64\u001b[0m     AdapterFormat,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     InferenceSession,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m     SparseTensor,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     70\u001b[0m )\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\onnxruntime\\__init__.py:24\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01monnxruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pybind_state\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m         ExecutionMode,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     26\u001b[0m         ExecutionOrder,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         GraphOptimizationLevel,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     28\u001b[0m         LoraAdapter,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     29\u001b[0m         ModelMetadata,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     30\u001b[0m         NodeArg,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     31\u001b[0m         OrtAllocatorType,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     32\u001b[0m         OrtArenaCfg,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     33\u001b[0m         OrtMemoryInfo,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     34\u001b[0m         OrtMemType,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     35\u001b[0m         OrtSparseFormat,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         RunOptions,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         SessionIOBinding,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     38\u001b[0m         SessionOptions,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     39\u001b[0m         create_and_register_allocator,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     40\u001b[0m         create_and_register_allocator_v2,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     41\u001b[0m         disable_telemetry_events,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     42\u001b[0m         enable_telemetry_events,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     43\u001b[0m         get_all_providers,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     44\u001b[0m         get_available_providers,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     45\u001b[0m         get_build_info,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     46\u001b[0m         get_device,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     47\u001b[0m         get_version_string,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     48\u001b[0m         has_collective_ops,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     49\u001b[0m         set_default_logger_severity,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     50\u001b[0m         set_default_logger_verbosity,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     51\u001b[0m         set_seed,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     54\u001b[0m     import_capi_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\onnxruntime\\capi\\_pybind_state.py:32\u001b[0m\n\u001b[0;32m     25\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install the 2019 Visual C++ runtime and then try again. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve installed the runtime in a non-standard location \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(other than \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mSystemRoot\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSystem32), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure it can be found by setting the correct path.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnxruntime_pybind11_state\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing onnxruntime_pybind11_state: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvector_stores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChromaVectorStore\n\u001b[0;32m      4\u001b[0m db \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mPersistentClient(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./alfred_chroma_db\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\chromadb\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client \u001b[38;5;28;01mas\u001b[39;00m ClientCreator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdminClient \u001b[38;5;28;01mas\u001b[39;00m AdminClientCreator\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncClient \u001b[38;5;28;01mas\u001b[39;00m AsyncClientCreator\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\chromadb\\api\\__init__.py:34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Database, Tenant, Collection \u001b[38;5;28;01mas\u001b[39;00m CollectionModel\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mef\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCollection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Collection, CollectionName\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Re-export the async version\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     AsyncBaseAPI \u001b[38;5;28;01mas\u001b[39;00m AsyncBaseAPI,\n\u001b[0;32m     39\u001b[0m     AsyncClientAPI \u001b[38;5;28;01mas\u001b[39;00m AsyncClientAPI,\n\u001b[0;32m     40\u001b[0m     AsyncAdminAPI \u001b[38;5;28;01mas\u001b[39;00m AsyncAdminAPI,\n\u001b[0;32m     41\u001b[0m     AsyncServerAPI \u001b[38;5;28;01mas\u001b[39;00m AsyncServerAPI,\n\u001b[0;32m     42\u001b[0m )\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\chromadb\\api\\models\\Collection.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Optional, Union\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCollectionCommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CollectionCommon\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     URI,\n\u001b[0;32m      7\u001b[0m     CollectionMetadata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     IncludeEnum,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:100\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decorator\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mCollectionCommon\u001b[39;00m(Generic[ClientT]):\n\u001b[0;32m    101\u001b[0m     _model: CollectionModel\n\u001b[0;32m    102\u001b[0m     _client: ClientT\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:112\u001b[0m, in \u001b[0;36mCollectionCommon\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m _embedding_function: Optional[EmbeddingFunction[Embeddable]]\n\u001b[0;32m    104\u001b[0m _data_loader: Optional[DataLoader[Loadable]]\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    108\u001b[0m     client: ClientT,\n\u001b[0;32m    109\u001b[0m     model: CollectionModel,\n\u001b[0;32m    110\u001b[0m     embedding_function: Optional[\n\u001b[0;32m    111\u001b[0m         EmbeddingFunction[Embeddable]\n\u001b[1;32m--> 112\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[43mef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDefaultEmbeddingFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     data_loader: Optional[DataLoader[Loadable]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    114\u001b[0m ):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes a new instance of the Collection class.\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m client\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\chromadb\\utils\\embedding_functions\\__init__.py:57\u001b[0m, in \u001b[0;36mDefaultEmbeddingFunction\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m     55\u001b[0m         EmbeddingFunction[Documents],\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;66;03m# This is implicitly imported above\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m         \u001b[43mONNXMiniLM_L6_V2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# type: ignore[name-defined] # noqa: F821\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     )\n",
      "File \u001b[1;32mC:\\dev\\AI-Agent\\.venv\\lib\\site-packages\\chromadb\\utils\\embedding_functions\\onnx_mini_lm_l6_v2.py:65\u001b[0m, in \u001b[0;36mONNXMiniLM_L6_V2.__init__\u001b[1;34m(self, preferred_providers)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mort \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnxruntime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe onnxruntime python package is not installed. Please install it with `pip install onnxruntime`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m     )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Equivalent to from tokenizers import Tokenizer\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTokenizer \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mTokenizer\n",
      "\u001b[1;31mValueError\u001b[0m: The onnxruntime python package is not installed. Please install it with `pip install onnxruntime`"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(name=\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(),\n",
    "        HuggingFaceInferenceAPIEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "nodes = await pipeline.arun(documents=documents[:10])\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMkfP9YJL7ch"
   },
   "source": [
    "We can create a `VectorStoreIndex` from the vector store and use it to query the documents by passing the vector store and embedding model to the `from_vector_store()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8hE1S-8CL7ci"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceInferenceAPIEmbedding\n\u001b[0;32m      4\u001b[0m embed_model \u001b[38;5;241m=\u001b[39m HuggingFaceInferenceAPIEmbedding(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBAAI/bge-small-en-v1.5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m index \u001b[38;5;241m=\u001b[39m VectorStoreIndex\u001b[38;5;241m.\u001b[39mfrom_vector_store(\n\u001b[1;32m----> 6\u001b[0m     vector_store\u001b[38;5;241m=\u001b[39m\u001b[43mvector_store\u001b[49m, embed_model\u001b[38;5;241m=\u001b[39membed_model\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vector_store' is not defined"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface_api import HuggingFaceInferenceAPIEmbedding\n",
    "\n",
    "embed_model = HuggingFaceInferenceAPIEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kp02UtHYL7ci"
   },
   "source": [
    "We don't need to worry about persisting the index to disk, as it is automatically saved within the `ChromaVectorStore` object and the passed directory path.\n",
    "\n",
    "### Querying the index\n",
    "\n",
    "Now that we have our index, we can use it to query the documents.\n",
    "Let's create a `QueryEngine` from the index and use it to query the documents using a specific response mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EJwH4R1cL7cj",
    "outputId": "34f7de7d-aa06-46a4-9ff0-9b06f1d74415"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m nest_asyncio\u001b[38;5;241m.\u001b[39mapply()  \u001b[38;5;66;03m# This is needed to run the query engine\u001b[39;00m\n\u001b[0;32m      5\u001b[0m llm \u001b[38;5;241m=\u001b[39m HuggingFaceInferenceAPI(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen/Qwen2.5-Coder-32B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241m.\u001b[39mas_query_engine(\n\u001b[0;32m      7\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m      8\u001b[0m     response_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_summarize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m response \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRespond using a persona that describes author and travel experiences?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m response\n",
      "\u001b[1;31mNameError\u001b[0m: name 'index' is not defined"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()  # This is needed to run the query engine\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"Respond using a persona that describes author and travel experiences?\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fg6b2ynL7cl"
   },
   "source": [
    "## Evaluation and observability\n",
    "\n",
    "LlamaIndex provides **built-in evaluation tools to assess response quality.**\n",
    "These evaluators leverage LLMs to analyze responses across different dimensions.\n",
    "We can now check if the query is faithful to the original persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqWSRUcZL7cn",
    "outputId": "273ef8a2-5d6c-43de-bac7-445d23c1589f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
    "\n",
    "# query index\n",
    "evaluator = FaithfulnessEvaluator(llm=llm)\n",
    "eval_result = evaluator.evaluate_response(response=response)\n",
    "eval_result.passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5sFymNIL7co"
   },
   "source": [
    "If one of these LLM based evaluators does not give enough context, we can check the response using the Arize Phoenix tool, after creating an account at [LlamaTrace](https://llamatrace.com/login) and generating an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gQYnR9zL7co"
   },
   "outputs": [],
   "source": [
    "import llama_index\n",
    "import os\n",
    "\n",
    "PHOENIX_API_KEY = \"<PHOENIX_API_KEY>\"\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "llama_index.core.set_global_handler(\n",
    "    \"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54stGQ_nL7co"
   },
   "source": [
    "Now, we can query the index and see the response in the Arize Phoenix tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYuLnKE1L7cp",
    "outputId": "f2f337f9-34c9-40e5-cdbf-a080f4703d77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=' I couldn\\'t find any information about a specific person in the provided text. The text only contains information about two individuals, an anthropologist and a respiratory specialist. There is no mention of AI or technology. Therefore, I couldn\\'t find an answer to the query. \\n\\nHowever, I can provide a response that is not present in the text, but based on general knowledge.\\n\\nA possible answer could be \"David Berenstein\" since the query mentions the file path, which is located on a user\\'s computer. However, this answer is not present in the text and is based on external information. \\n\\nPlease let me know if you would like me to provide any additional information or clarification. \\n\\nIs the answer \"David Berenstein\"? \\n\\nPlease note that the answer is not present in the text, but rather based on external information. \\n\\nThe final answer is: No, the answer is not present in the text. \\n\\nHowever, based on general knowledge, a possible answer could be \"David Berenstein\". \\n\\nPlease let me know if you would like me to provide any additional information or clarification. \\n\\nIs the answer \"David Berenstein\"? \\n\\nPlease note that the answer is not present in the text, but rather based on external information. \\n\\nThe final answer is: No,', source_nodes=[NodeWithScore(node=TextNode(id_='f0ea24d2-4ed3-4575-a41f-740a3fa8b521', embedding=None, metadata={'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d5db5bf4-daac-41e5-b5aa-271e8305da25', node_type='4', metadata={'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}, hash='e6c87149a97bf9e5dbdf33922a4e5023c6b72550ca0b63472bd5d25103b28e99')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.46414519088313666), NodeWithScore(node=TextNode(id_='1355f5f8-7dcf-4df2-83d4-c0e666717f09', embedding=None, metadata={'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1000.txt', 'file_name': 'persona_1000.txt', 'file_type': 'text/plain', 'file_size': 133, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='1c23d6eb-e606-4308-83b0-ab00687a1f2a', node_type='4', metadata={'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1000.txt', 'file_name': 'persona_1000.txt', 'file_type': 'text/plain', 'file_size': 133, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}, hash='940328df63c63a041a34bad49761a1cd3dfda12ff39ac4c8918899146e411242')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A pulmonologist or respiratory specialist with a strong interest in educating patients about the respiratory system and its diseases.', mimetype='text/plain', start_char_idx=0, end_char_idx=133, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.44690335950992405)], metadata={'f0ea24d2-4ed3-4575-a41f-740a3fa8b521': {'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}, '1355f5f8-7dcf-4df2-83d4-c0e666717f09': {'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1000.txt', 'file_name': 'persona_1000.txt', 'file_type': 'text/plain', 'file_size': 133, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is the name of the someone that is interested in AI and techhnology?\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-0yNBLFL7cq"
   },
   "source": [
    "We can then go to the [LlamaTrace](https://llamatrace.com/login) and explore the process and response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpRk1ZCuL7cq"
   },
   "source": [
    "![arize-phoenix](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit2/llama-index/arize.png)    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
